---
title: "Diana's models"
author: "Diana Fay Arbas"
date: "2023-06-22"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Diana's models

# Load data

```{r}

# Load the required packages
library(ggplot2)
library(gridExtra)
library(caret)
library(tidyverse)
library(corrplot)
library(dplyr)
library(ggfortify)
library(MLmetrics) 
library(pROC)


# Import dataset as a csv file from GitHub
sleep <- read.csv("https://raw.githubusercontent.com/VSbr22/ADS503-Group-Project/main/sleep.csv")
head(sleep)

```

# Convert mutli-class target variable to binary

```{r}

Sleep.Disorder.Binary = as.character(sleep$Sleep.Disorder)
Sleep.Disorder.Binary[Sleep.Disorder.Binary=="Insomnia" ] = "Yes"
Sleep.Disorder.Binary[Sleep.Disorder.Binary=="Sleep Apnea" ] = "Yes"
Sleep.Disorder.Binary[Sleep.Disorder.Binary=="None" ] = "No"
Sleep.Disorder.Binary = factor(Sleep.Disorder.Binary, levels=c("Yes","No") )
sleep_binary <- cbind(sleep, Sleep.Disorder.Binary)
head(sleep_binary)

```

# Split into training and test

```{r}

set.seed(100)
training <- createDataPartition(y = sleep_binary$Sleep.Disorder, p = 0.8, list = FALSE)

# Split into testing and training sets.
train <- sleep_binary[training, ]
test <- sleep_binary[-training, ]
head(train)

```

# Drop Person.ID and Sleep.Disorder

```{r}

library(dplyr)

train <- select(train, -Person.ID, -Sleep.Disorder)
test <- select(test, -Person.ID, -Sleep.Disorder)
head(train)

```

# Split Blood.Pressure into Systolic and Diastolic

```{r}

# Create two new columns for Blood pressure
train <- train %>% separate(Blood.Pressure, into = c("Systolic", "Diastolic"), sep = "/", convert = TRUE)
test <- test %>% separate(Blood.Pressure, into = c("Systolic", "Diastolic"), sep = "/", convert = TRUE)

# make them numeric 
train$Systolic <- as.numeric(train$Systolic)
train$Diastolic <- as.numeric(train$Diastolic)
test$Systolic <- as.numeric(test$Systolic)
test$Diastolic <- as.numeric(test$Diastolic)

```

# Subset numerical and categorical

```{r}

# Numerical predictors are Age, Sleep.Duration, Quality.of.Sleep, Physical.Activity.Level, Stress.Level, Systolic, Diastolic, Heart.Rate, and Daily.Steps
# Categorical predictors are Gender, Occupation, and BMI.Category
# Subset numerical for preprocessing
train_num <- train[, c("Age", "Sleep.Duration", "Quality.of.Sleep", "Physical.Activity.Level", "Stress.Level", "Systolic", "Diastolic", "Heart.Rate", "Daily.Steps")]
test_num <- test[, c("Age", "Sleep.Duration", "Quality.of.Sleep", "Physical.Activity.Level", "Stress.Level", "Systolic", "Diastolic", "Heart.Rate", "Daily.Steps")]

```

# Preprocess numerical predictors
# No zero-variance predictors

```{r}

# Identify near-zero variance predictors
near_zero_vars <- nearZeroVar(train_num, saveMetrics = TRUE)

# View the near-zero variance predictors
near_zero_vars

```

# Centering and scaling

```{r}

preProcValues <- preProcess(train_num,
                            method = c("center", "scale", "medianImpute"))
train_num_trans <- predict(preProcValues, train_num)
test_num_trans <- predict(preProcValues, test_num)

```


# Convert categorical into dummy variables

```{r}

library(caret)

# Subset categorical
categorical <- c("Gender", "Occupation", "BMI.Category")
train_cat <- train[, categorical]
test_cat <- test[, categorical]

# Create dummy variables for train
formula <- "~ ."
dummy_vars <- dummyVars(formula, data = train_cat)
train_dummy <- data.frame(predict(dummy_vars, newdata = train_cat))
# Create dummy variables for test
formula <- "~ ."
dummy_vars <- dummyVars(formula, data = test_cat)
test_dummy <- data.frame(predict(dummy_vars, newdata = test_cat))

# test_dummy is missing OccupationManager, OccupationSales.Representative, OccupationScientist, OccupationSoftware.Engineer
# To make sure train_dummy and test_dummy have the same columns, 
# I will add the missing columns to test_dummy and fill them with zeroes

test_dummy$OccupationManager <- 0
test_dummy$OccupationSales.Representative <- 0
test_dummy$OccupationScientist <- 0
test_dummy$OccupationSoftware.Engineer <- 0

```

# Combine numerical, dummy, and binary target variable

```{r}

combined_train <- cbind(train_num_trans, train_dummy, Sleep.Disorder.Binary = train$Sleep.Disorder.Binary)

combined_test <- cbind(test_num_trans, test_dummy, Sleep.Disorder.Binary = test$Sleep.Disorder.Binary)

```


# Subset X and Y

```{r}

trainX <- combined_train[, -ncol(combined_train)]
trainY <- data.frame(Sleep.Disorder.Binary = combined_train$Sleep.Disorder.Binary)
testX <- combined_test[, -ncol(combined_test)]
testY <- data.frame(Sleep.Disorder.Binary = combined_test$Sleep.Disorder.Binary)

```


# Handle highly correlated predictors

```{r}

# Calculate correlation matrix
cor_matrix <- cor(trainX)

# Set the correlation threshold
cor_threshold <- 0.8  

# Find highly correlated predictor pairs
highly_correlated <- which(upper.tri(cor_matrix, diag = TRUE) & abs(cor_matrix) > cor_threshold, arr.ind = TRUE)

# Get the names of highly correlated predictors
highly_correlated_names <- rownames(cor_matrix)[highly_correlated[, 1]]
correlated_pairs <- cbind(highly_correlated_names, colnames(cor_matrix)[highly_correlated[, 2]])

# Print the correlated predictor pairs
print(correlated_pairs)

```


Sleep.Duration and Quality.of.Sleep, Sleep.Duration and Stress.Level, and Quality.of.Sleep and Stress.Level are highly correlated pairs. So I will drop Quality.of.Sleep and Stress.Level, which seem more subjective than Sleep.Duration.


# Drop Quality.of.Sleep and Stress.Level

```{r}

trainX <- trainX[, !(colnames(trainX) %in% c("Quality.of.Sleep", "Stress.Level"))]
testX <- testX[, !(colnames(testX) %in% c("Quality.of.Sleep", "Stress.Level"))]

```


# Logistic Regression Model

```{r}

suppressWarnings({

ctrl <- trainControl(method = "cv",
                     summaryFunction = multiClassSummary,
                     classProbs = TRUE,
                     savePredictions = TRUE)

set.seed(100)

lrFit <- train(x = trainX, 
               y = train$Sleep.Disorder.Binary,
               method = "glm",
               metric = "ROC",
               trControl = ctrl)

lrFit$finalModel

})

```

# Logistic Regression Model Accuracy = 91.8%

```{r}

lrPred <- predict(lrFit, newdata = testX)
lrCM <- confusionMatrix(lrPred, test$Sleep.Disorder.Binary)
lrCM

```

# Plot the ROC curve for the hold-out set

```{r}

lrRoc <- roc(response = lrFit$pred$obs,
             predictor = lrFit$pred$Yes,
             levels = rev(levels(lrFit$pred$obs)))

plot(lrRoc, legacy.axes = TRUE)

```

# The area under the curve: 0.869.

```{r}

lrRoc$auc

```

# Important variables

```{r}

lrImp <- varImp(lrFit, scale = FALSE)
plot(lrImp)

```

# Store results for model comparison later

```{r}

testResults <- data.frame(obs = testY, 
                          LR = predict(lrFit, testX))

```


## Linear Discriminant Analysis Model

```{r}

suppressWarnings({

set.seed(100)
ldaFit <- train(x = trainX,
                y = train$Sleep.Disorder.Binary,
                method = "lda",
                preProc = c("center", "scale"),
                metric = "ROC",
                trControl = ctrl)

ldaFit$finalModel

})

```

# Linear Discriminant Analysis Model Accuracy = 83.6%

```{r}

suppressWarnings({

ldaPred <- predict(ldaFit, newdata = testX)
ldaCM <- confusionMatrix(ldaPred, test$Sleep.Disorder.Binary)
ldaCM

})

```

# Plot the ROC curve for the hold-out set

```{r}

ldaRoc <- roc(response = ldaFit$pred$obs,
              predictor = ldaFit$pred$Yes,
              levels = rev(levels(ldaFit$pred$obs)))

plot(ldaRoc, legacy.axes = TRUE)

```


# The area under the curve: 0.931

```{r}

ldaRoc$auc

```


# Important variables

```{r}

plot(varImp(ldaFit, scale = FALSE))

```


# Storing predictions in testResults for later

```{r}

testResults$LDA <- predict(ldaFit, testX)

```

## Nearest Shrunken Centroids Model

```{r}

glmnGrid <- expand.grid(alpha = c(0, .1, .2, .4, .6, .8, 1),
                        lambda = seq(0.1, .2, length = 10))

set.seed(100)
glmnFit <- train(x = trainX,
                 y = train$Sleep.Disorder.Binary,
                 method = "glmnet",
                 tuneGrid = glmnGrid,
                 preProc = c("center", "scale"),
                 metric = "ROC",
                 trControl = ctrl)

glmnFit$results

```

## Nearest Shrunken Centroids Model Accuracy: 89%

```{r}

nscPred <- predict(glmnFit, newdata = testX)
nscCM <- confusionMatrix(nscPred, test$Sleep.Disorder.Binary)
nscCM

```
      
                      
# Plot                      
                      
```{r}

plot(glmnFit$finalModel, label = TRUE)
coef(glmnFit$finalModel, s = 100)
coef(glmnFit$finalModel, s = 0.001)
glmnFit$finalModel$lambda
glmnFit$finalModel$tuneValue
glmnFit$finalModel$lambdaOpt
coef(glmnFit$finalModel, s = glmnFit$finalModel$lambdaOpt)

```


## Plot the ROC curve for the hold-out set

```{r}

glmRoc <- roc(response = glmnFit$pred$obs,
              predictor = glmnFit$pred$Yes,
              levels = rev(levels(glmnFit$pred$obs)))

plot(glmRoc, legacy.axes = TRUE) 

```


## The nearest shrunken centroids model's area under the curve: 0.941

```{r}

glmRoc$auc

```


# Important variables

```{r}

plot(varImp(glmnFit, scale = FALSE))

```


## Store model predictions for later

```{r}

testResults$glmnet <- predict(glmnFit, testX)
testResults

```




                 
